# å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰è¬›ç¾© - Databricks ãƒãƒ³ã‚ºã‚ªãƒ³

å¤§å­¦ãªã©ã®è¬›ç¾©ï¼ˆ90åˆ†ï¼‰ã§ä½¿ç”¨ã™ã‚‹ã€Databricksç’°å¢ƒã§ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®å®Ÿè·µçš„ãªãƒãƒ³ã‚ºã‚ªãƒ³æ•™æã§ã™ã€‚Foundation Model APIã‹ã‚‰ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€MLflowã«ã‚ˆã‚‹è©•ä¾¡ãƒ»ç®¡ç†ã¾ã§ã€LLMã®åŸºç¤ã‹ã‚‰æœ¬ç•ªé‹ç”¨ã¾ã§ä½“ç³»çš„ã«å­¦ç¿’ã§ãã¾ã™ã€‚

## ğŸ“š æ¦‚è¦

æœ¬æ•™æã¯ã€ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’ã‚«ãƒãƒ¼ã™ã‚‹6ã¤ã®Exerciseã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ï¼š

1. **Exercise 1**: Chat Completion APIã®åŸºæœ¬
2. **Exercise 2**: Structured Outputsã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
3. **Exercise 3**: Function Callingã®åŸºç¤
4. **Exercise 4**: HuggingFaceãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ
5. **Exercise 5**: LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
6. **Exercise 6**: MLflowã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨å®Ÿé¨“ç®¡ç† â­ **NEW**

## ğŸ¯ å­¦ç¿’ç›®æ¨™

- Databricks Foundation Model APIã®ä½¿ç”¨æ–¹æ³•ã‚’ç¿’å¾—
- Structured Outputsã¨Function Callingã®å®Ÿè£…
- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆGemma 3 270Mï¼‰ã®æ´»ç”¨
- LoRAã‚’ä½¿ã£ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- **MLflowã«ã‚ˆã‚‹å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã¨ãƒ¢ãƒ‡ãƒ«ç®¡ç†** â­ **NEW**
- **LLMè©•ä¾¡æŒ‡æ¨™ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹** â­ **NEW**
- **Model Registryã‚’ä½¿ã£ãŸæœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤** â­ **NEW**
- å®Ÿå‹™ã§ä½¿ãˆã‚‹LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºã‚¹ã‚­ãƒ«ã®ç²å¾—

## ğŸ“‹ å‰ææ¡ä»¶

### å¿…é ˆ
- Databricksç’°å¢ƒã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆFree Editionä»¥ä¸Šï¼‰
- PythonåŸºç¤çŸ¥è­˜
- æ©Ÿæ¢°å­¦ç¿’ã®åŸºæœ¬çš„ãªç†è§£

### æ¨å¥¨
- GPUå¯¾å¿œã‚¯ãƒ©ã‚¹ã‚¿ï¼ˆExercise 5, 6ã§ä½¿ç”¨ï¼‰
- MLflowã®åŸºç¤çŸ¥è­˜ï¼ˆExercise 6ï¼‰

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. Databricksç’°å¢ƒã®æº–å‚™

**Databricks Free Edition**
```
1. https://www.databricks.com/try-databricks ã«ã‚¢ã‚¯ã‚»ã‚¹
2. ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆ
3. Notebookã‚’æ–°è¦ä½œæˆ
```

### 2. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

å„Exerciseã®Notebookå†’é ­ã§ä»¥ä¸‹ãŒè‡ªå‹•å®Ÿè¡Œã•ã‚Œã¾ã™ï¼š

```
# Exercise 1-3
%pip install --upgrade databricks-sdk openai pydantic

# Exercise 4-5
%pip install --upgrade transformers datasets accelerate peft trl bitsandbytes sentencepiece

# Exercise 6
%pip install --upgrade transformers datasets evaluate rouge-score bert-score sacrebleu nltk peft torch mlflow
```

### 3. HuggingFace Tokenã®è¨­å®šï¼ˆExercise 4-6ï¼‰

Gemma 3ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€HuggingFaceã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¿…è¦ã§ã™ï¼š

1. [HuggingFace](https://huggingface.co/)ã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ
2. [Gemma 3 270M-IT](https://huggingface.co/google/gemma-3-270m-it)ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«åŒæ„
3. [Tokensãƒšãƒ¼ã‚¸](https://huggingface.co/settings/tokens)ã§Readæ¨©é™ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆ
4. Notebookã§èªè¨¼:
```
from huggingface_hub import login
login(token="your_token_here")
```

## ğŸ“– Exerciseæ¦‚è¦

### Exercise 1: Chat Completion APIã®åŸºæœ¬ï¼ˆ8åˆ†ï¼‰

**ç›®çš„**: Databricks Foundation Model APIã®åŸºæœ¬çš„ãªä½¿ã„æ–¹ã‚’ç†è§£ã™ã‚‹

**å†…å®¹**:
- WorkspaceClientã®åˆæœŸåŒ–
- ã‚·ãƒ³ãƒ—ãƒ«ãªè³ªå•å¿œç­”
- ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŠ¹æœ
- Temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´
- ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã®å®Ÿè£…
- ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®ç›£è¦–

**ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«**: `databricks-meta-llama-3-3-70b-instruct`

**ä¸»ãªå­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ**:
```
from databricks.sdk import WorkspaceClient

w = WorkspaceClient()
client = w.serving_endpoints.get_open_ai_client()

response = client.chat.completions.create(
    model="databricks-meta-llama-3-3-70b-instruct",
    messages=[
        {"role": "user", "content": "æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ"}
    ],
    max_tokens=256,
    temperature=0.7
)
```

### Exercise 2: Structured Outputsã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆ12åˆ† + ãŠã¾ã‘5åˆ†ï¼‰

**ç›®çš„**: éæ§‹é€ åŒ–ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹å®Ÿè·µçš„ã‚¹ã‚­ãƒ«ã‚’ç¿’å¾—

**å†…å®¹**:
- Pydanticã«ã‚ˆã‚‹ã‚¹ã‚­ãƒ¼ãƒå®šç¾©
- JSON Schemaã‚’ä½¿ã£ãŸæ§‹é€ åŒ–å‡ºåŠ›
- é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è‡ªå‹•åˆ†æ
- DataFrameã¸ã®å¤‰æ›ã¨ãƒ“ã‚¸ãƒã‚¹åˆ†æ
- ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨å“è³ªç®¡ç†
- **ãŠã¾ã‘**: Databricksãƒãƒƒãƒæ¨è«–ï¼ˆai_queryã€Pandas UDFã€Streamingï¼‰

**ãƒ“ã‚¸ãƒã‚¹ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹**: Eã‚³ãƒãƒ¼ã‚¹é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æ

**ä¸»ãªå­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ**:
```
from pydantic import BaseModel, Field
from typing import Literal

class ReviewAnalysis(BaseModel):
    product_name: str = Field(description="è£½å“å")
    rating: int = Field(description="è©•ä¾¡ï¼ˆ1-5ã®æ•´æ•°ï¼‰")
    sentiment: Literal["positive", "negative", "neutral"]

response = client.chat.completions.create(
    model="databricks-meta-llama-3-3-70b-instruct",
    messages=[...],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "review_analysis",
            "schema": ReviewAnalysis.model_json_schema(),
            "strict": True
        }
    }
)
```

### Exercise 3: Function Callingã®åŸºç¤ï¼ˆ10åˆ†ï¼‰

**ç›®çš„**: LLMãŒå¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™ä»•çµ„ã¿ã‚’ç†è§£ã—ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºç›¤ã‚’æ§‹ç¯‰

**å†…å®¹**:
- ãƒ„ãƒ¼ãƒ«å®šç¾©ï¼ˆå¤©æ°—æƒ…å ±ã€åœ¨åº«ç¢ºèªã€é…é€æ–™é‡‘è¨ˆç®—ï¼‰
- ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã§ã®ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
- è¤‡æ•°ãƒ„ãƒ¼ãƒ«ã‹ã‚‰ã®è‡ªå‹•é¸æŠ
- tool_choiceãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆ¶å¾¡
- æ¬¡å›ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¬›ç¾©ã¸ã®æ©‹æ¸¡ã—

**ãƒ“ã‚¸ãƒã‚¹ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹**: ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆãƒœãƒƒãƒˆ

**ä¸»ãªå­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ**:
```
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "æŒ‡å®šã•ã‚ŒãŸéƒ½å¸‚ã®ç¾åœ¨ã®å¤©æ°—æƒ…å ±ã‚’å–å¾—ã—ã¾ã™",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {"type": "string"},
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                },
                "required": ["location"]
            }
        }
    }
]

response = client.chat.completions.create(
    model="databricks-meta-llama-3-3-70b-instruct",
    messages=[{"role": "user", "content": "æ±äº¬ã®å¤©æ°—ã‚’æ•™ãˆã¦"}],
    tools=tools,
    tool_choice="auto"
)
```

### Exercise 4: HuggingFaceãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œï¼ˆ15åˆ†ï¼‰

**ç›®çš„**: Foundation Model APIä»¥å¤–ã®é¸æŠè‚¢ã¨ã—ã¦ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥ä½¿ç”¨

**å†…å®¹**:
- HuggingFace Hubã‹ã‚‰ã®ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
- `apply_chat_template`ã‚’ä½¿ã£ãŸæ­£ã—ã„ãƒãƒ£ãƒƒãƒˆå½¢å¼
- Pipeline APIã¨low-level APIã®ä½¿ã„åˆ†ã‘
- ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã®å®Ÿè£…
- æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ï¼ˆè³ªå•å¿œç­”ã€è¦ç´„ã€åˆ†é¡ï¼‰ã§ã®è©•ä¾¡
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šã¨ãƒ¡ãƒ¢ãƒªç®¡ç†
- ãƒãƒƒãƒæ¨è«–

**ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«**: [google/gemma-3-270m-it](https://huggingface.co/google/gemma-3-270m-it)

**ä¸»ãªå­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ**:
```
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

# æ–¹æ³•1: Low-level API
tokenizer = AutoTokenizer.from_pretrained("google/gemma-3-270m-it")
model = AutoModelForCausalLM.from_pretrained(
    "google/gemma-3-270m-it",
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

messages = [{"role": "user", "content": "è‡ªå·±ç´¹ä»‹ã—ã¦ãã ã•ã„"}]
inputs = tokenizer.apply_chat_template(
    messages,
    add_generation_prompt=True,
    tokenize=True,
    return_dict=True,
    return_tensors="pt"
).to(model.device)

outputs = model.generate(**inputs, max_new_tokens=100)

# æ–¹æ³•2: Pipeline API
pipe = pipeline("text-generation", model="google/gemma-3-270m-it")
result = pipe(messages)
```

### Exercise 5: LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆ20åˆ† + ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°15-30åˆ†ï¼‰

**ç›®çš„**: LoRAã‚’ä½¿ã£ãŸåŠ¹ç‡çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè·µ

**å†…å®¹**:
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ã¨ãƒãƒ£ãƒƒãƒˆå½¢å¼ã¸ã®å¤‰æ›
- 4-bité‡å­åŒ–ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªå‰Šæ¸›
- LoRAè¨­å®šã¨PEFTãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä½¿ç”¨
- SFTTrainerã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å‰å¾Œã®æ€§èƒ½æ¯”è¼ƒ
- ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨ãƒ­ãƒ¼ãƒ‰

**ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: [bbz662bbz/databricks-dolly-15k-ja-gozarinnemon](https://huggingface.co/datasets/bbz662bbz/databricks-dolly-15k-ja-gozarinnemon)
- Databricks Dolly 15kã®æ—¥æœ¬èªè¨³ç‰ˆ
- å›ç­”ã®èªå°¾ãŒã€Œã”ã–ã‚‹ã€å£èª¿ï¼ˆåŠ¹æœãŒè¦–è¦šçš„ã«ç¢ºèªã—ã‚„ã™ã„ï¼‰

**ä¸»ãªå­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ**:
```
from peft import LoraConfig, prepare_model_for_kbit_training
from trl import SFTTrainer, SFTConfig

# LoRAè¨­å®š
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    task_type="CAUSAL_LM"
)

# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
trainer = SFTTrainer(
    model=model,
    args=sft_config,
    train_dataset=dataset['train'],
    eval_dataset=dataset['test'],
    tokenizer=tokenizer,
    peft_config=lora_config
)

trainer.train()
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡**:
- å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°: 270Mï¼ˆ100%ï¼‰
- LoRAï¼ˆr=16ï¼‰: ç´„0.5Mï¼ˆ0.2%ï¼‰
- **å‰Šæ¸›ç‡**: 99.8%

### Exercise 6: MLflowã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨å®Ÿé¨“ç®¡ç†ï¼ˆ20åˆ†ï¼‰â­ **NEW**

**ç›®çš„**: MLflowã‚’ä½¿ã£ãŸå®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã€ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã€æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ã‚’å­¦ã¶

**å†…å®¹**:
- MLflowã«ã‚ˆã‚‹å®Ÿé¨“ã®è‡ªå‹•ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
- è©•ä¾¡æŒ‡æ¨™ï¼ˆBLEUã€ROUGEã€BERTScoreï¼‰ã®è¨˜éŒ²
- MLflow Datasetsã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ç®¡ç†
- ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡æŒ‡æ¨™ã®å®šç¾©
- LLM-as-a-Judgeã®å®Ÿè£…ã¨ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
- Model Registryã¸ã®ç™»éŒ²ã¨ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°
- Model Servingã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆãƒ‡ãƒ¢ï¼‰
- ç·åˆè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã®è‡ªå‹•ç”Ÿæˆ

**Databricksç‰¹æœ‰ã®æ©Ÿèƒ½**:
- MLflow UIã§ã®å®Ÿé¨“æ¯”è¼ƒ
- Unity Catalogã¨ã®çµ±åˆ
- Lakehouse Monitoringã¸ã®æ¥ç¶š

**ä¸»ãªå­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ**:
```
import mlflow
import mlflow.transformers

# MLflowå®Ÿé¨“ã®è¨­å®š
mlflow.set_experiment("/Users/your-name/llm-evaluation")

# è©•ä¾¡å®Ÿè¡Œã¨ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
with mlflow.start_run(run_name="finetuned-model-eval") as run:
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ã‚°
    mlflow.log_input(dataset_source, context="evaluation")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°
    mlflow.log_param("model_name", model_id)
    mlflow.log_param("num_parameters", model.num_parameters())
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ã‚°
    mlflow.log_metric("bleu_score", bleu_result['score'])
    mlflow.log_metric("rouge1_score", rouge_result['rouge1'])
    mlflow.log_metric("bertscore_f1", f1_score)
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²
    mlflow.transformers.log_model(
        transformers_model={"model": model, "tokenizer": tokenizer},
        artifact_path="model",
        registered_model_name="gemma-3-270m-finetuned"
    )
```

**è©•ä¾¡æŒ‡æ¨™**:
1. **è‡ªå‹•è©•ä¾¡**
   - BLEU: n-gramãƒ™ãƒ¼ã‚¹ã®ç²¾åº¦æ¸¬å®š
   - ROUGE: å†ç¾ç‡ãƒ™ãƒ¼ã‚¹ã®è¦ç´„è©•ä¾¡
   - BERTScore: æ„å‘³çš„é¡ä¼¼åº¦ã®æ¸¬å®š

2. **ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡**
   - ã‚¹ã‚¿ã‚¤ãƒ«ä¸€è²«æ€§ï¼ˆã”ã–ã‚‹å£èª¿ä½¿ç”¨ç‡ï¼‰
   - å¿œç­”é•·ã®åˆ†æ
   - æ¨è«–é€Ÿåº¦ã®æ¸¬å®š

3. **LLM-as-a-Judge**
   - å¼·åŠ›ãªLLMã«ã‚ˆã‚‹å“è³ªè©•ä¾¡
   - äººé–“ã®åˆ¤æ–­ã«ã‚ˆã‚Šè¿‘ã„è©•ä¾¡
   - èª¬æ˜å¯èƒ½æ€§ã®é«˜ã„è©•ä¾¡

**Model Registryã¨ãƒ‡ãƒ—ãƒ­ã‚¤**:
```
from mlflow.tracking import MlflowClient

client = MlflowClient()

# ãƒ¢ãƒ‡ãƒ«ã‚’Stagingã«æ˜‡æ ¼
client.transition_model_version_stage(
    name="gemma-3-270m-finetuned",
    version="1",
    stage="Staging"
)

# æ€§èƒ½åŸºæº–ã‚’æº€ãŸã›ã°Productionã«æ˜‡æ ¼
if meets_production_criteria:
    client.transition_model_version_stage(
        name="gemma-3-270m-finetuned",
        version="1",
        stage="Production"
    )
```

## ğŸ’¡ æ¨å¥¨å­¦ç¿’é †åº

### è¬›ç¾©å†…ï¼ˆ90åˆ†ï¼‰
1. **Exercise 1 â†’ 2 â†’ 3**: Foundation Model APIã®åŸºç¤ã‹ã‚‰å¿œç”¨ï¼ˆ30åˆ†ï¼‰
2. **Exercise 4**: ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ç†è§£ï¼ˆ15åˆ†ï¼‰
3. **Exercise 5**: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œï¼ˆæ¼”ç¿’ã¨ã—ã¦é–‹å§‹ï¼‰

### è¬›ç¾©å¾Œã®ç™ºå±•å­¦ç¿’
4. **Exercise 5**: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ã®ç¢ºèª
5. **Exercise 6**: MLflowã«ã‚ˆã‚‹è©•ä¾¡ã¨æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆé‡è¦ï¼‰â­

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Databricks Workspace                        â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Foundation Model â”‚   â”‚ HuggingFace Models  â”‚             â”‚
â”‚  â”‚ API              â”‚   â”‚ (Gemma 3 270M)      â”‚             â”‚
â”‚  â”‚ - Llama 3.3 70B  â”‚   â”‚ - Direct inference  â”‚             â”‚
â”‚  â”‚ - Gemini         â”‚   â”‚ - LoRA fine-tuning  â”‚             â”‚
â”‚  â”‚ - Qwen           â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚         â†“                        â†“                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Applications                                  â”‚            â”‚
â”‚  â”‚ - Structured Output (Review Analysis)        â”‚            â”‚
â”‚  â”‚ - Function Calling (Customer Support)        â”‚            â”‚
â”‚  â”‚ - Custom Domain (Fine-tuned models)          â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ MLflow (Experiment Management) â­ NEW         â”‚            â”‚
â”‚  â”‚ - Experiment Tracking                         â”‚            â”‚
â”‚  â”‚ - Model Registry                              â”‚            â”‚
â”‚  â”‚ - Model Serving                               â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Data Processing                               â”‚            â”‚
â”‚  â”‚ - ai_query() for batch inference             â”‚            â”‚
â”‚  â”‚ - Pandas UDF for complex logic               â”‚            â”‚
â”‚  â”‚ - Structured Streaming for real-time         â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š æœ¬ç•ªäº‹ä¾‹ï¼ˆExercise 2ã§ç´¹ä»‹ï¼‰

1. **UiPath - ä¼æ¥­æ–‡æ›¸ã®æ§‹é€ åŒ–æŠ½å‡º**
   - DocPath: è«‹æ±‚æ›¸ã€é ˜åæ›¸ã€ç¨å‹™æ›¸é¡ã®è‡ªå‹•å‡¦ç†
   - Structured Outputsã«ã‚ˆã‚‹ä½ç½®æƒ…å ±ä»˜ãæŠ½å‡º
   - è‡ªå‹•åŒ–ç‡200%å‘ä¸Š

2. **Morgan Stanley - é¡§å®¢ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°è­°äº‹éŒ²ã®è‡ªå‹•æ§‹é€ åŒ–**
   - AI @ Morgan Stanley Debrief
   - 98%ã®Financial Advisorãƒãƒ¼ãƒ ãŒæ¡ç”¨
   - 1ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚ãŸã‚Š30åˆ†ã®æ™‚é–“å‰Šæ¸›

3. **Klarna - ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆè‡ªå‹•åŒ–**
   - 1å„„5000ä¸‡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€1æ—¥250ä¸‡ä»¶ã®å–å¼•å‡¦ç†
   - 700äººåˆ†ã®ãƒ•ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ¥­å‹™ã‚’ä»£æ›¿
   - å¹³å‡è§£æ±ºæ™‚é–“ã‚’80%å‰Šæ¸›

## ğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Exercise 2: "Invalid JSON schema - integer types do not support minimum"

**åŸå› **: Databricks strict ãƒ¢ãƒ¼ãƒ‰ã§ã¯ `ge`/`le` åˆ¶ç´„ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„

**è§£æ±ºç­–**: 
```
# âŒ ä½¿ç”¨ä¸å¯
rating: int = Field(ge=1, le=5)

# âœ… æ­£ã—ã„æ–¹æ³•
rating: int = Field(description="è©•ä¾¡ï¼ˆ1-5ã®æ•´æ•°ï¼‰")
```

### Exercise 2 ãƒãƒƒãƒæ¨è«–: "default auth: cannot configure default credentials"

**åŸå› **: Pandas UDFå†…ã§WorkspaceClientãŒèªè¨¼ã§ããªã„

**è§£æ±ºç­–**: ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã§èªè¨¼æƒ…å ±ã‚’å–å¾—ã—ã€ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå¤‰æ•°ã§é…å¸ƒ
```
w = WorkspaceClient()
token = w.config.token
broadcast_token = spark.sparkContext.broadcast(token)

# UDFå†…ã§ä½¿ç”¨
token = broadcast_token.value
client = OpenAI(api_key=token, base_url=...)
```

### Exercise 4-5: GPU not available

**è§£æ±ºç­–**: 
1. Serverless GPUã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
2. GPUå¯¾å¿œã‚¯ãƒ©ã‚¹ã‚¿ï¼ˆg4dn.xlargeä»¥ä¸Šï¼‰ã‚’èµ·å‹•
3. Databricks Runtime 14.3 MLä»¥é™ã‚’é¸æŠ

### Exercise 5: Out of Memory Error

**è§£æ±ºç­–**:
```
# ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
per_device_train_batch_size=2  # 4 â†’ 2

# å‹¾é…ç´¯ç©ã‚¹ãƒ†ãƒƒãƒ—ã‚’å¢—åŠ ï¼ˆå®ŸåŠ¹ãƒãƒƒãƒã‚µã‚¤ã‚ºç¶­æŒï¼‰
gradient_accumulation_steps=8  # 4 â†’ 8

# å‹¾é…ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æœ‰åŠ¹åŒ–ï¼ˆæ—¢ã«æœ‰åŠ¹ï¼‰
gradient_checkpointing=True
```

### Exercise 6: MLflowå®Ÿé¨“ãŒè¦‹ã¤ã‹ã‚‰ãªã„ â­ **NEW**

**åŸå› **: å®Ÿé¨“åã®ãƒ‘ã‚¹ãŒæ­£ã—ããªã„

**è§£æ±ºç­–**:
```
# ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å‹•çš„ã«å–å¾—
username = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()
experiment_name = f"/Users/{username}/llm-evaluation"
mlflow.set_experiment(experiment_name)
```

## ğŸ“š å‚è€ƒè³‡æ–™

### å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [Databricks Foundation Model APIs](https://docs.databricks.com/machine-learning/foundation-model-apis/)
- [Databricks Structured Outputs](https://docs.databricks.com/machine-learning/model-serving/structured-outputs)
- [Databricks Function Calling](https://docs.databricks.com/machine-learning/model-serving/function-calling)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html) â­ **NEW**
- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html) â­ **NEW**
- [Gemma 3 Model Card](https://huggingface.co/google/gemma-3-270m-it)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)
- [PEFT Documentation](https://huggingface.co/docs/peft/)

### æŠ€è¡“ãƒ–ãƒ­ã‚°ãƒ»è«–æ–‡
- [Attention is All You Need (2017)](https://arxiv.org/abs/1706.03762) - Transformerã®åŸè«–æ–‡
- [LoRA: Low-Rank Adaptation](https://arxiv.org/abs/2106.09685)
- [Databricks: Introducing Structured Outputs](https://www.databricks.com/blog/introducing-structured-outputs-batch-and-agent-workflows)
- [MLflow: A Platform for Managing the Machine Learning Lifecycle](https://mlflow.org/docs/latest/index.html) â­ **NEW**

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

ãƒã‚°å ±å‘Šã€æ”¹å–„ææ¡ˆã€æ–°ã—ã„Exerciseã®ã‚¢ã‚¤ãƒ‡ã‚¢ãªã©ã€ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ­“è¿ã—ã¾ã™ã€‚

1. ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ã‚¯
2. æ–°ã—ã„ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ (`git checkout -b feature/amazing-exercise`)
3. å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ (`git commit -m 'Add amazing exercise'`)
4. ãƒ–ãƒ©ãƒ³ãƒã«ãƒ—ãƒƒã‚·ãƒ¥ (`git push origin feature/amazing-exercise`)
5. Pull Requestã‚’ä½œæˆ

## ğŸ“ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯[LICENSE](LICENSE)ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

```
MIT License

Copyright (c) 2025 [Your Name]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## ğŸ™ è¬è¾

æœ¬æ•™æã¯ä»¥ä¸‹ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å‚è€ƒã«ã—ã¦ã„ã¾ã™ï¼š
- Databrickså…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰
- Google Gemma 3ãƒãƒ¼ãƒ ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- HuggingFace Transformersã¨PEFTãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- Databricks Dolly 15kæ—¥æœ¬èªè¨³ï¼ˆkunishouæ°ï¼‰ã¨gozarinneç‰ˆï¼ˆbbz662bbzæ°ï¼‰
- MLflowé–‹ç™ºãƒãƒ¼ãƒ ã¨ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ â­ **NEW**

---

**Happy Learning! ğŸš€**

**Powered by Databricks + MLflow** â­
